{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....Starting chapter 4 \n"
     ]
    }
   ],
   "source": [
    "print(\"....Starting chapter 4 \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\":50257,\n",
    "    \"context_length\":1024,\n",
    "    \"emb_dim\":768,\n",
    "    \"n_heads\":12,\n",
    "    \"n_layers\":12,\n",
    "    \"drop_rate\":0.1,\n",
    "    \"bias_\":False\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DummyGPTModel(nn.Module):\n",
    "    def __init__(self, cfg): # ----->cfg stands for configuration of the model\n",
    "        super().__init__()\n",
    "        self.token_embedding=nn.Embedding(cfg['vocab_size'],cfg['emb_dim'])\n",
    "        self.positional_embedding=nn.Embedding(cfg['context_length'],cfg['emb_dim'])\n",
    "        self.drop_emnd=nn.Dropout(cfg['drop_rate'])\n",
    "        self.transformer_blocks= nn.Sequential(\n",
    "            *[DummyTransformerBlock(cfg)\n",
    "              for _ in range(cfg['n_layers'])]\n",
    "        )\n",
    "        self.final_norm=DummyLayerNorm(cfg['emb_dim'])\n",
    "\n",
    "        self.out_head=nn.Linear(\n",
    "            cfg['emb_dim'],cfg['vocab_size']\n",
    "            ,bias=False\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self,in_idx):\n",
    "        batch_size , seq_len= in_idx.shape\n",
    "\n",
    "        tok_embeds=self.token_embedding(in_idx)\n",
    "        pos_embeds=self.positional_embedding(\n",
    "            torch.arange(seq_len,device=in_idx.device)\n",
    "        ) \n",
    "\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x=self.drop_emnd(x)\n",
    "        x=self.transformer_blocks(x)\n",
    "        x=self.final_norm(x)\n",
    "\n",
    "        logits=self.out_head(x)\n",
    "\n",
    "        return logits\n",
    "    \n",
    "\n",
    "class DummyTransformerBlock(nn.Module):\n",
    "    def __init__(self,cfg ):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self,x):\n",
    "        return x \n",
    "\n",
    "class DummyLayerNorm(nn.Module):\n",
    "    def __init__(self,normalizerd_shape,eps=1e-5 ):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self,x):\n",
    "        return x                   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   40, 13721, 15461,   220],\n",
       "        [   40,   716,   281, 11949]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "GPT_toknizer=tiktoken.get_encoding('gpt2')\n",
    "batch=[]\n",
    "txt1=\"I regret pursuing \"\n",
    "txt2=\"I am an engineer\"\n",
    "\n",
    "batch.append(torch.tensor(GPT_toknizer.encode(txt1)))\n",
    "batch.append(torch.tensor(GPT_toknizer.encode(txt2)))\n",
    "\n",
    "batch=torch.stack(batch,dim=0)\n",
    "\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 50257])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(69)\n",
    "\n",
    "model=DummyGPTModel(GPT_CONFIG_124M)\n",
    "\n",
    "logits=model(batch)\n",
    "\n",
    "\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.7629,  0.2764, -0.4752,  ..., -0.5381, -0.0084,  1.0804],\n",
       "         [-0.8403, -0.6271,  0.7980,  ..., -0.0748, -1.7378,  0.9352],\n",
       "         [ 0.2350,  1.0148,  0.7561,  ..., -1.6156, -0.4738, -0.8695],\n",
       "         [ 0.8994, -1.1139,  0.1895,  ..., -0.3196,  0.0101,  0.3780]],\n",
       "\n",
       "        [[-0.0655, -0.2674, -0.1463,  ..., -0.4391,  0.1845,  1.0390],\n",
       "         [-0.7170,  0.2430,  0.8741,  ..., -0.4582, -0.1968,  0.1792],\n",
       "         [ 1.0623,  0.7679,  0.7557,  ..., -1.2531, -0.0161, -0.3236],\n",
       "         [ 0.3861, -0.1189, -0.1243,  ...,  1.0454, -0.2871,  0.7292]]],\n",
       "       grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1514, 0.0000, 0.2192, 0.0000, 0.3302, 0.0000],\n",
      "        [0.2511, 0.0000, 0.0000, 0.1048, 0.2901, 0.0000]],\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(69)\n",
    "\n",
    "inputs=torch.rand(2,5)\n",
    "demoNN=nn.Sequential(\n",
    "    nn.Linear(5,6),\n",
    "    nn.ReLU()\n",
    ")\n",
    "out=demoNN(inputs)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1168],\n",
       "        [0.1077]], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.sum(dim=-1,keepdim=True)/out.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1168],\n",
       "        [0.1077]], grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean=out.mean(dim=-1,keepdim=True)\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0196],\n",
       "        [0.0177]], grad_fn=<VarBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variance=out.var(dim=-1,keepdim=True)\n",
    "variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_outputs = (out - mean)/torch.sqrt(variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_mean=normalized_outputs.mean(dim=-1,keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_variance=normalized_outputs.var(dim=-1,keepdim=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: tensor([[    0.0000],\n",
      "        [    0.0000]], grad_fn=<MeanBackward1>)\n",
      "variance: tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(sci_mode=False)\n",
    "print(\"mean:\",normalized_mean)\n",
    "print(\"variance:\",normalized_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps=1e-5\n",
    "        self.scale=nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift=nn.Parameter(torch.zeros(emb_dim))\n",
    "    def forward(self,x):\n",
    "        mean=x.mean(dim=-1,keepdim=True)\n",
    "        var=x.var(dim=-1,keepdim=True , unbiased=False)\n",
    "        norm_x=(x-mean) / torch.sqrt(var+self.eps)\n",
    "        return self.scale * norm_x + self.shift\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6072, 0.5147, 0.7654, 0.5434, 0.3774],\n",
       "        [0.3056, 0.6771, 0.3802, 0.2426, 0.8268]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_example=torch.rand(2,5)\n",
    "batch_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: tensor([[    -0.0000],\n",
      "        [     0.0000]], grad_fn=<MeanBackward1>)\n",
      "variance:\n",
      " tensor([[0.9994],\n",
      "        [0.9998]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "ln = LayerNorm(emb_dim=5)\n",
    "out_ln=ln(batch_example)\n",
    "mean=out_ln.mean(dim=-1,keepdim=True)\n",
    "var=out_ln.var(dim=-1,keepdim=True,unbiased=False)\n",
    "print('mean:',mean)\n",
    "print(\"variance:\\n\",var)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Gelu(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(torch.sqrt(torch.tensor(2 / torch.pi)) * (x + 0.044715 * torch.pow(x, 3))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.9546)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gelu=Gelu()\n",
    "gelu(torch.tensor(2.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.9546)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as f\n",
    "gelu=f.gelu(torch.tensor(2.),approximate='tanh')\n",
    "gelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hp/y1d826dx5fb1405ppnjjm4700000gn/T/ipykernel_57390/394656700.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return 0.5 * x * (1 + torch.tanh(torch.sqrt(torch.tensor(2 / torch.pi)) * torch.tensor((x + 0.044715 * torch.pow(x, 3)))))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define the functions\n",
    "def gelu(x):\n",
    "    return 0.5 * x * (1 + torch.tanh(torch.sqrt(torch.tensor(2 / torch.pi)) * torch.tensor((x + 0.044715 * torch.pow(x, 3)))))\n",
    "\n",
    "def relu(x):\n",
    "    return torch.maximum(torch.tensor(0.0), x)\n",
    "\n",
    "# Generate x values\n",
    "x_vals = torch.linspace(-3, 3, 100)\n",
    "\n",
    "# Compute function values\n",
    "gelu_vals = gelu(x_vals)\n",
    "relu_vals = relu(x_vals)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot GELU\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(x_vals.numpy(), gelu_vals.numpy(), label=\"GELU\", color=\"b\")\n",
    "plt.title(\"GELU (Smooth)\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"f(x)\")\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot ReLU\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(x_vals.numpy(), relu_vals.numpy(), label=\"ReLU\", color=\"r\")\n",
    "plt.title(\"ReLU (Not Smooth)\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"f(x)\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFN(nn.Module):\n",
    "    def __init__(self,cfg ):\n",
    "        super().__init__()\n",
    "        self.layers=nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"],4 * cfg[\"emb_dim\"]),\n",
    "            Gelu(),\n",
    "            nn.Linear(4 * cfg[\"emb_dim\"],cfg[\"emb_dim\"])\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        return self.layers(x)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hp/y1d826dx5fb1405ppnjjm4700000gn/T/ipykernel_57390/2699759041.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(torch.rand(2,3,768))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 768])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffn=FFN(\n",
    "    GPT_CONFIG_124M\n",
    ")\n",
    "x = torch.tensor(torch.rand(2,3,768))\n",
    "out=ffn(x)\n",
    "out.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EXResidualConnections(nn.Module):\n",
    "    def __init__(self,layer_sizes,use_shortcut):\n",
    "        super().__init__()\n",
    "        self.use_shortcut=use_shortcut\n",
    "        self.layers=nn.ModuleList([\n",
    "            nn.Sequential(nn.Linear(layer_sizes[0],layer_sizes[1]),\n",
    "                          Gelu()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[1],layer_sizes[2]),\n",
    "                          Gelu()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[2],layer_sizes[3]),\n",
    "                          Gelu()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[3],layer_sizes[4]),\n",
    "                          Gelu()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[4],layer_sizes[5]),\n",
    "                          Gelu())\n",
    "        ])            \n",
    "    def forward(self,x):\n",
    "        for layer in self.layers:\n",
    "            layer_output=layer(x)\n",
    "            if self.use_shortcut and x.shape==layer_output.shape:\n",
    "                x=x+layer_output\n",
    "            else:\n",
    "                x=layer_output\n",
    "        return x             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(69)\n",
    "layer_sizes=[3,3,3,3,3,1]\n",
    "sample_input = torch.rand(1,3)\n",
    "model_without_skip_connections = EXResidualConnections(\n",
    "    layer_sizes,use_shortcut=False\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_gradients(model , x):\n",
    "    output = model(x)\n",
    "    target = torch.tensor([[0.]])\n",
    "\n",
    "    loss=nn.MSELoss()\n",
    "    loss=loss(output,target)\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    for name,param in model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            print(f'{name} has gradient mean of {param.grad.abs().mean().item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 3.2735970307840034e-05\n",
      "layers.1.0.weight has gradient mean of 4.1062277887249365e-05\n",
      "layers.2.0.weight has gradient mean of 6.823352305218577e-05\n",
      "layers.3.0.weight has gradient mean of 0.0008357462356798351\n",
      "layers.4.0.weight has gradient mean of 0.003820376703515649\n"
     ]
    }
   ],
   "source": [
    "print_gradients(model_without_skip_connections,sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.06841462850570679\n",
      "layers.1.0.weight has gradient mean of 0.0576305128633976\n",
      "layers.2.0.weight has gradient mean of 0.03812249377369881\n",
      "layers.3.0.weight has gradient mean of 0.03064136952161789\n",
      "layers.4.0.weight has gradient mean of 0.45960965752601624\n"
     ]
    }
   ],
   "source": [
    "# now we define a model which has skip connections \n",
    "torch.manual_seed(69)\n",
    "\n",
    "model_with_skip_connections=EXResidualConnections(\n",
    "    layer_sizes,use_shortcut=True\n",
    ")\n",
    "print_gradients(model_with_skip_connections,sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert (d_out % num_heads == 0), \\\n",
    "        \"d_out must be divisible by num_heads\"\n",
    "        \n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads\n",
    "        \n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out, d_out)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.register_buffer(\n",
    "            \"mask\",\n",
    "            torch.triu(torch.ones(context_length, context_length),\n",
    "                      diagonal=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "        \n",
    "        # Linear transformations\n",
    "        keys = self.W_key(x)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "        \n",
    "        # Reshape to include heads dimension\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        \n",
    "        # Compute attention scores\n",
    "        attn_scores = queries @ keys.transpose(-2, -1)\n",
    "        \n",
    "        # Apply mask\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "        \n",
    "        # Compute attention weights\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "        \n",
    "        # Compute context vectors\n",
    "        context_vec = attn_weights @ values\n",
    "        context_vec = context_vec.transpose(1, 2).contiguous().view(b, num_tokens, self.d_out)\n",
    "        context_vec = self.out_proj(context_vec)\n",
    "        \n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "\n",
    "        self.attention=MultiHeadAttention(\n",
    "            d_in=cfg['emb_dim'],\n",
    "            d_out=cfg['emb_dim'],\n",
    "            context_length=cfg['context_length'],\n",
    "            num_heads=cfg['n_heads'],\n",
    "            dropout=cfg['drop_rate'],\n",
    "            qkv_bias=cfg['bias_']\n",
    "\n",
    "        )\n",
    "        self.ff=FFN(cfg)\n",
    "        self.norm1=LayerNorm(cfg['emb_dim'])\n",
    "        self.norm2=LayerNorm(cfg['emb_dim'])\n",
    "        self.dropout=nn.Dropout(cfg['drop_rate'])\n",
    "\n",
    "    def forward(self,x):\n",
    "        shortcut=x\n",
    "        x=self.norm1(x)\n",
    "        x=self.attention(x)\n",
    "        x=self.dropout(x)\n",
    "        x=x+shortcut\n",
    "\n",
    "\n",
    "        shortcut=x\n",
    "        x=self.norm2(x)\n",
    "        x=self.ff(x)\n",
    "        x=self.dropout(x)\n",
    "        x=x+shortcut\n",
    "        return x \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 768])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(69)\n",
    "x=torch.rand(2,4,768) # a batch with 4 input tokens and each token has a dimension of 768\n",
    "block=TransformerBlock(GPT_CONFIG_124M)\n",
    "output=block(x)\n",
    "output.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb=nn.Embedding(cfg['vocab_size'],cfg['emb_dim'])\n",
    "        self.pos_emb=nn.Embedding(cfg['context_length'],cfg['emb_dim'])\n",
    "        self.drop_emb=nn.Dropout(cfg['drop_rate'])\n",
    "\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg['n_layers'])]\n",
    "        )\n",
    "        self.final_norm=LayerNorm(cfg['emb_dim'])\n",
    "        self.out_head=nn.Linear(\n",
    "            cfg['emb_dim'],cfg['vocab_size'],bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self,in_idx):  # -----> in idx stands for the input ids the model will recieve \n",
    "        batch_size,seq_len = in_idx.shape\n",
    "        token_embds=self.tok_emb(in_idx)\n",
    "\n",
    "        pos_emb=self.pos_emb(\n",
    "            torch.arange(seq_len,device=in_idx.device))\n",
    "\n",
    "        x=token_embds + pos_emb\n",
    "        x=self.drop_emb(x)\n",
    "        x=self.trf_blocks(x)\n",
    "        x=self.final_norm(x)\n",
    "        logits=self.out_head(x)\n",
    "        return logits\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(69)\n",
    "model=GPTModel(GPT_CONFIG_124M)\n",
    "\n",
    "out=model(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 50257])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the total number of parameters: 163,009,536\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"the total number of parameters: {total_params:,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable paramters is 124,412,160 using weight tying\n"
     ]
    }
   ],
   "source": [
    "GPT_124M_params=(\n",
    "    total_params - sum(p.numel()\n",
    "    for p in model.out_head.parameters())\n",
    ")\n",
    "print(f\"Number of trainable paramters is {GPT_124M_params:,} using weight tying\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of ffn parameters:4,722,432\n",
      "number of multi head attention parameters:2,360,064\n"
     ]
    }
   ],
   "source": [
    "ffn_number_of_params=(\n",
    "    sum(p.numel()\n",
    "        for p in block.ff.parameters())\n",
    ")\n",
    "\n",
    "attn_block_num_params=(\n",
    "    sum(p.numel() \n",
    "        for p in block.attention.parameters())\n",
    ")\n",
    "print(f'number of ffn parameters:{ffn_number_of_params:,}')\n",
    "print(f'number of multi head attention parameters:{attn_block_num_params:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerBlock(\n",
       "  (attention): MultiHeadAttention(\n",
       "    (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "    (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "    (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (ff): FFN(\n",
       "    (layers): Sequential(\n",
       "      (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (1): Gelu()\n",
       "      (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (norm1): LayerNorm()\n",
       "  (norm2): LayerNorm()\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size of the model:621.83 MB\n"
     ]
    }
   ],
   "source": [
    "total_size_bytes=total_params * 4  # 1byte = bits \n",
    "total_size_mb = total_size_bytes / (1024 *1024) # 1mb = 1024 x 1024 bytes\n",
    "print(f'Total size of the model:{total_size_mb:.2f} MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exercise 4.2\n",
    "\n",
    "GPT_MEDIUM_CONFIG = {\n",
    "    \"vocab_size\":50257,\n",
    "    \"context_length\":1024,\n",
    "    \"emb_dim\":1024,\n",
    "    \"n_heads\":16,\n",
    "    \"n_layers\":24,\n",
    "    \"drop_rate\":0.1,\n",
    "    \"bias_\":False\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 1024)\n",
       "  (pos_emb): Embedding(1024, 1024)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (12): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (13): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (14): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (15): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (16): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (17): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (18): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (19): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (20): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (21): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (22): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (23): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=1024, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPT_MEDIUM = GPTModel(GPT_MEDIUM_CONFIG)\n",
    "GPT_MEDIUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_MEDIUM_NUM_OF_PARAMS = sum(p.numel() for p in GPT_MEDIUM.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUMBER OF PARAMETERS IN GPT-M: 406,212,608\n"
     ]
    }
   ],
   "source": [
    "print(f'NUMBER OF PARAMETERS IN GPT-M: {GPT_MEDIUM_NUM_OF_PARAMS:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exercise 4.2\n",
    "\n",
    "GPT_LARGE_CONFIG = {\n",
    "    \"vocab_size\":50257,\n",
    "    \"context_length\":1024,\n",
    "    \"emb_dim\":1280,\n",
    "    \"n_heads\":20,\n",
    "    \"n_layers\":36,\n",
    "    \"drop_rate\":0.1,\n",
    "    \"bias_\":False\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_LARGE = GPTModel(GPT_LARGE_CONFIG)\n",
    "GPT_LARGE_NUM_OF_PARAMS = sum(p.numel() for p in GPT_LARGE.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUMBER OF PARAMETERS IN GPT-L: 838,220,800\n"
     ]
    }
   ],
   "source": [
    "print(f'NUMBER OF PARAMETERS IN GPT-L: {GPT_LARGE_NUM_OF_PARAMS:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_X_LARGE_CONFIG = {\n",
    "    \"vocab_size\":50257,\n",
    "    \"context_length\":1024,\n",
    "    \"emb_dim\":1600,\n",
    "    \"n_heads\":25,\n",
    "    \"n_layers\":48,\n",
    "    \"drop_rate\":0.1,\n",
    "    \"bias_\":False\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_X_LARGE = GPTModel(GPT_X_LARGE_CONFIG)\n",
    "GPT_X_LARGE_NUM_OF_PARAMS = sum(p.numel() for p in GPT_X_LARGE.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUMBER OF PARAMETERS IN GPT-XL: 1,637,792,000\n"
     ]
    }
   ],
   "source": [
    "print(f'NUMBER OF PARAMETERS IN GPT-XL: {GPT_X_LARGE_NUM_OF_PARAMS:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_simple(model,idx,                     #---->idx is a shape of (batch,ntokens)\n",
    "                        max_new_tokens,context_size ):  \n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_condn=idx[: , -context_size:]  #---> truncation part if the input exceeds the context size\n",
    "        with torch.no_grad():\n",
    "            logits=model(idx_condn)\n",
    "\n",
    "        logits=logits[: , -1 , :]     # here this part focuses only on the last time step \n",
    "        probas = torch.softmax(logits , dim=-1) # converting the logits to probabilities of the last token \n",
    "        idx_next=torch.argmax(probas,dim=-1,keepdim=True)  # finding the token with the highest probability\n",
    "        idx=torch.cat((idx,idx_next),dim=-1)      # appends the new token to the previous input\n",
    "\n",
    "    return idx       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded_input:  [25374, 314, 3001, 402, 11571, 9447, 7036, 29125, 1268, 1961, 11050, 220]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_context = \"HI I AM GPT SMALL TRAINED BY \"\n",
    "encoded = GPT_toknizer.encode(start_context)\n",
    "print('encoded_input: ',encoded)\n",
    "encoded_tensor=torch.tensor(encoded).unsqueeze(0)\n",
    "encoded_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[25374,   314,  3001,   402, 11571,  9447,  7036, 29125,  1268,  1961,\n",
      "         11050,   220, 15832, 18006, 25893, 17028, 32241, 28452, 39621,  5993,\n",
      "         25911, 15290]])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "out=generate_text_simple(\n",
    "    model=model,\n",
    "    idx=encoded_tensor,\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M['context_length']\n",
    ")\n",
    "print(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_text=GPT_toknizer.decode(\n",
    "    out.squeeze(0).tolist()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HI I AM GPT SMALL TRAINED BY  formally Wildlife excuses consultant SunnyMechiframeamily Basketball mock'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
