{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... starting with CHAPTER 5\n"
     ]
    }
   ],
   "source": [
    "print(\"... starting with CHAPTER 5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from chap4 import GPTModel\n",
    "from chap4 import GPT_CONFIG_124M\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M={\n",
    "'vocab_size': 50257,\n",
    " 'context_length': 256,\n",
    " 'emb_dim': 768,\n",
    " 'n_heads': 12,\n",
    " 'n_layers': 12,\n",
    " 'drop_rate': 0.1,\n",
    " 'bias_': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vocab_size': 50257,\n",
       " 'context_length': 256,\n",
       " 'emb_dim': 768,\n",
       " 'n_heads': 12,\n",
       " 'n_layers': 12,\n",
       " 'drop_rate': 0.1,\n",
       " 'bias_': False}"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPT_CONFIG_124M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "model = GPTModel(GPT_CONFIG_124M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "from chap4 import generate_text_simple\n",
    "\n",
    "def text_to_token_ids(text,tokenizer):\n",
    "    encoded=tokenizer.encode(text,allowed_special={\"<|endoftext|>\"})\n",
    "    encoded_tensor=torch.tensor(encoded).unsqueeze(0)\n",
    "    return encoded_tensor\n",
    "\n",
    "\n",
    "def token_ids_to_text(input_ids, tokenizer):\n",
    "    flat = input_ids.squeeze(0)\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "start_context=\"मेरा नाम भाव्य गोयल है \"\n",
    "tokenizer=tiktoken.get_encoding('gpt2')\n",
    "\n",
    "token_ids=generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context,tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M['context_length'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11976,   106, 24231,   229, 11976,   108, 48077, 28225,   101, 48077,\n",
       "         11976,   106, 28225,   255, 48077, 11976,   113, 24231,   235, 11976,\n",
       "           107, 28225,   245, 24231,   233, 11976,   107, 11976,   110, 28225,\n",
       "           117, 24231,   230,   220,  5302, 23906, 30013,  6104,  5970, 21213,\n",
       "         30311,  2266, 33192, 26071]])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_text = token_ids_to_text(token_ids,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'मेरा नाम भाव्य गोयल है  Jo720 trackerEven incor beard Gujarat red robe acoustic'"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8]), torch.Size([8]))"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1=\"My name is 777GPT Model \"\n",
    "text2=\"I am inspired by ILYA \"\n",
    "encoded_txt1=torch.tensor(tokenizer.encode(text1))\n",
    "encoded_txt2=torch.tensor(tokenizer.encode(text2))\n",
    "encoded_txt1.shape,encoded_txt2.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_batch=torch.stack((encoded_txt1,encoded_txt2),dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3666,  1438,   318, 35534,    38, 11571,  9104,   220],\n",
       "        [   40,   716,  7867,   416,   314, 11319,    32,   220]])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_text1='name is 777GPT I'\n",
    "target_text2='am inspired by Ilya ,'\n",
    "decoded_target_txt1=torch.tensor(tokenizer.encode(target_text1))\n",
    "decoded_target_txt2=torch.tensor(tokenizer.encode(target_text2))\n",
    "decoded_target_txt1.shape,decoded_target_txt2.shape\n",
    "output_target=torch.stack((decoded_target_txt1,decoded_target_txt2),dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6]), torch.Size([6]))"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_target_txt1.shape,decoded_target_txt2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100], # [\"every effort moves\",\n",
    "[40, 1107, 588]]) # \"I really like\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[16833,  3626,  6100],\n",
       "        [   40,  1107,   588]])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = torch.tensor([[3626, 6100, 345 ], # [\" effort moves you\",\n",
    "[1107, 588, 11311]]) # \" really like chocolate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3626,  6100,   345],\n",
       "        [ 1107,   588, 11311]])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 50257])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob=torch.softmax(logits,dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 50257])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[16657,   339, 42826],\n",
       "        [49906, 29669, 41751]])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_tokens=torch.argmax(prob,dim=-1)\n",
    "predicted_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target batch 1:  effort moves you\n",
      "the converted text1:  Armed heNetflix\n",
      "target for batch 2  really like chocolate\n",
      "the converted text:  pressuring empoweredfaith\n"
     ]
    }
   ],
   "source": [
    "print('target batch 1:',token_ids_to_text(targets[0],tokenizer))\n",
    "print('the converted text1:',token_ids_to_text(predicted_tokens[0],tokenizer))\n",
    "print('target for batch 2',token_ids_to_text(targets[1],tokenizer))\n",
    "print('the converted text:',token_ids_to_text(predicted_tokens[1],tokenizer))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    0.0000,     0.0001,     0.0000])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_probas1=prob[1,[0,1,2],targets[1]]\n",
    "target_probas1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_probas2=prob[0,[0,1,2],targets[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_probas=torch.log(\n",
    "    torch.cat((target_probas1,target_probas2))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-11.4798,  -9.7764, -12.2561,  -9.5042, -10.3796, -11.3677])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_log_probas = torch.mean(log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.7940)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_avg_log_prob = -1 * avg_log_probas\n",
    "neg_avg_log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits shape: torch.Size([2, 3, 50257])\n",
      "targets shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "print('logits shape:',logits.shape)\n",
    "print('targets shape:',targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flattened logits: torch.Size([6, 50257])\n",
      "Flattened Targets:  torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flatten=logits.flatten(0,1)\n",
    "targets_flatten=targets.flatten()\n",
    "print(\"flattened logits:\",logits_flatten.shape)\n",
    "print(\"Flattened Targets: \",targets_flatten.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "loss=torch.nn.functional.cross_entropy(logits_flatten,targets_flatten)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(48725.8203)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "perplexity = torch.exp(loss)\n",
    "perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20479\n"
     ]
    }
   ],
   "source": [
    "file_path='the-verdict.txt'\n",
    "with open(file_path,'r') as file:\n",
    "    text_data=file.read()\n",
    "print(len(text_data))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5145\n"
     ]
    }
   ],
   "source": [
    "print(len(tokenizer.encode(text_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.90\n",
    "split_idx=int(train_ratio * len(text_data))\n",
    "train_data=text_data[:split_idx]\n",
    "val_data=text_data[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader,Dataset\n",
    "\n",
    "def create_dataloader_v1(txt,batch_size=4,max_length=267,\n",
    "                         stride=128,shuffle=True,drop_last=True,\n",
    "                         num_workers=0):\n",
    "    bpe_tokenizer=tiktoken.get_encoding('gpt2')\n",
    "    dataset=GPTDatasetV1(txt,bpe_tokenizer,max_length,stride)\n",
    "    dataloader=DataLoader(dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers)\n",
    "    \n",
    "    return dataloader\n",
    "\n",
    "\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self,text,tokenizer,max_length,stride):\n",
    "        super().__init__()\n",
    "        self.input_ids=[]\n",
    "        self.target_ids=[]\n",
    "\n",
    "        token_ids=tokenizer.encode(text)\n",
    "\n",
    "\n",
    "        for i in range(0,len(token_ids)-max_length,stride):\n",
    "            input_chunk=token_ids[i:i+max_length]\n",
    "            target_chunk=token_ids[i+1:i+max_length+1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx],self.target_ids[idx]\n",
    "    \n",
    "\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_dataloader = create_dataloader_v1(\n",
    "    txt=train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M['context_length'],\n",
    "    stride=GPT_CONFIG_124M['context_length'],\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_dataloader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M['context_length'],\n",
    "    stride=GPT_CONFIG_124M['context_length'],\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=0\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Train loader')\n",
    "for x,y in train_dataloader:\n",
    "    print(x.shape,y.shape)\n",
    "len(train_dataloader)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL loader\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print('VAL loader')\n",
    "for x,y in val_dataloader:\n",
    "    print(x.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch,target_batch,model,device):\n",
    "    input_batch = input_batch.to(device)\n",
    "    target_batch= target_batch.to(device)\n",
    "    logits=model(input_batch)\n",
    "    loss=torch.nn.functional.cross_entropy(\n",
    "        logits.flatten(0,1),target_batch.flatten()\n",
    "    )\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_loader_data(data_loader , model ,device,num_batches=None):\n",
    "    total_loss=0\n",
    "    if len(data_loader) == 0 :\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches=len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches,len(data_loader))\n",
    "    for i , (input_batch,target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(\n",
    "                input_batch,target_batch,model,device\n",
    "            ) \n",
    "            total_loss+=loss.item()\n",
    "        else:\n",
    "            break\n",
    "        return total_loss/num_batches           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 1.2200181749131944\n",
      "validation loss: 10.981106758117676\n"
     ]
    }
   ],
   "source": [
    "device=torch.device('cpu')\n",
    "model.to(device)\n",
    "with torch.no_grad():\n",
    "    train_loss=calc_loss_loader_data(model=model,device=device,data_loader=train_dataloader)\n",
    "    val_loss=calc_loss_loader_data(model=model,device=device,data_loader=val_dataloader)\n",
    "print(\"training loss:\",train_loss)\n",
    "print('validation loss:',val_loss)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluate_model(model,train_dataloader,val_dataloader,eval_iter):\n",
    "#     model.eval()\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         train_loss = calc_loss_loader_data(\n",
    "#             train_dataloader,model,device,num_batches=eval_iter\n",
    "#         )\n",
    "#         val_loss = calc_loss_loader_data(\n",
    "#             val_dataloader,model,device,num_batches=eval_iter\n",
    "#         )\n",
    "#     model.train()\n",
    "#     return train_loss,val_loss  \n",
    "\n",
    "\n",
    "\n",
    "# def generate_and_print_sample(model,tokenizer,device,start_context):\n",
    "#     model.eval()\n",
    "#     context_size=model.pos_emb.weight.shape[0].to(device)\n",
    "#     encoded = text_to_token_ids(start_context,tokenizer).to(device)\n",
    "#     with torch.no_grad():\n",
    "#         token_ids = generate_text_simple(\n",
    "#             model=model,idx=encoded,max_new_tokens=50,context_size=context_size\n",
    "#         )\n",
    "#     decoded_text = token_ids_to_text(token_ids,tokenizer)\n",
    "#     print(decoded_text.replace(\"\\n\",\" \")) \n",
    "#     model.train()   \n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "# def train_model_simple(model,train_dataloader,val_dataloader,\n",
    "#                        optimizer,device,num_epochs,eval_freq,\n",
    "#                        eval_iter,start_context,tokenizer):\n",
    "#     train_losses,val_losses,track_tokens_seen = [],[],[]\n",
    "#     tokens_seen , global_step = 0,-1\n",
    "\n",
    "#     for epoch in range(num_epochs):\n",
    "#         model.train()\n",
    "#         for input_batch,target_batch in train_dataloader:\n",
    "#             optimizer.zero_grad()\n",
    "#             loss=calc_loss_batch(\n",
    "#                 input_batch,target_batch,model=model,device=device\n",
    "#             )\n",
    "#             loss.backward()  # this calculates gradients \n",
    "#             optimizer.step()  # updates gradient\n",
    "#             tokens_seen +=input_batch.numel()\n",
    "#             global_step+=1\n",
    "\n",
    "#             if global_step % eval_freq ==0:\n",
    "#                 train_loss,val_loss,= evaluate_model(\n",
    "#                     model,train_dataloader,val_dataloader,eval_iter\n",
    "#                 )\n",
    "#                 train_losses.append(train_loss)\n",
    "#                 train_losses.append(train_loss)\n",
    "#                 val_losses.append(val_loss)\n",
    "#                 track_tokens_seen.append(track_tokens_seen)\n",
    "#                 print(f'Ep {epoch+1} (step {global_step:06d})):'\n",
    "#                       f'train loss {train_loss:.3f}',\n",
    "#                       f'Val loss {val_loss:3f}' )\n",
    "#         generate_and_print_sample(\n",
    "#             model , tokenizer , device , start_context\n",
    "#         )\n",
    "#     return train_losses,val_losses,track_tokens_seen    \n",
    "\n",
    "\n",
    "def evaluate_model(model, train_dataloader, val_dataloader, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader_data(\n",
    "            train_dataloader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "        val_loss = calc_loss_loader_data(\n",
    "            val_dataloader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]  # No need to .to(device)\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded, max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "    \n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))\n",
    "    model.train()\n",
    "\n",
    "\n",
    "def train_model_simple(model, train_dataloader, val_dataloader,\n",
    "                       optimizer, device, num_epochs, eval_freq,\n",
    "                       eval_iter, start_context, tokenizer):\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for input_batch, target_batch in train_dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = calc_loss_batch(\n",
    "                input_batch, target_batch, model=model, device=device\n",
    "            )\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_dataloader, val_dataloader, eval_iter\n",
    "                )\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)  # Fix here\n",
    "                \n",
    "                print(f'Ep {epoch+1} (step {global_step:06d}): '\n",
    "                      f'Train loss {train_loss:.3f} | Val loss {val_loss:.3f}')\n",
    "\n",
    "        generate_and_print_sample(model, tokenizer, device, start_context)\n",
    "    \n",
    "    return train_losses, val_losses, track_tokens_seen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (step 000000): Train loss 2.110 | Val loss 10.576\n",
      "Ep 1 (step 000005): Train loss 1.817 | Val loss 9.417\n",
      "My name is ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
      "Ep 2 (step 000010): Train loss 1.759 | Val loss 8.876\n",
      "Ep 2 (step 000015): Train loss 1.675 | Val loss 8.403\n",
      "My name is  the the, the the the the the the the the the the the.                                   \n",
      "Ep 3 (step 000020): Train loss 1.590 | Val loss 7.983\n",
      "Ep 3 (step 000025): Train loss 1.491 | Val loss 7.585\n",
      "My name is , the, the the, the, the, the, the, the, the, the the,, the,, the, the, the, the the, the, the, the,, the, the, the, the, the\n",
      "Ep 4 (step 000030): Train loss 1.340 | Val loss 7.238\n",
      "Ep 4 (step 000035): Train loss 1.309 | Val loss 6.975\n",
      "My name is , the, and the the the the the, the, I had the, and, I had the, the, I had the, and the, and the the, the the of the, and the, and the, and, the of\n",
      "Ep 5 (step 000040): Train loss 1.209 | Val loss 6.857\n",
      "My name is , and I had the the of the the to the of the of the of the, I had the, I had                          \n",
      "Ep 6 (step 000045): Train loss 1.105 | Val loss 6.606\n",
      "Ep 6 (step 000050): Train loss 1.050 | Val loss 6.561\n",
      "My name is  the the, and I had been.        \"I was the, and I was, and I had been the, and I had been the his pictures--I had the, and I had been.  \n",
      "Ep 7 (step 000055): Train loss 0.968 | Val loss 6.417\n",
      "Ep 7 (step 000060): Train loss 0.855 | Val loss 6.344\n",
      "My name is  I had been.    \"--I was a little. \"I was--I--I, I had been to the I was his I was his pictures--I--I had the, and I had been.  \n",
      "Ep 8 (step 000065): Train loss 0.860 | Val loss 6.394\n",
      "Ep 8 (step 000070): Train loss 0.774 | Val loss 6.336\n",
      "My name is  I had been, and I felt--I to the fact of the.            \"--I he had the his pictures--I had been his he had been the--and, and I had\n",
      "Ep 9 (step 000075): Train loss 0.658 | Val loss 6.290\n",
      "Ep 9 (step 000080): Train loss 0.665 | Val loss 6.223\n",
      "My name is  I had been his pictures--I had been--I had a little of a.         \"I. I, and I had been his pictures--I had been the, and--I had been his pictures\n",
      "Ep 10 (step 000085): Train loss 0.640 | Val loss 6.294\n",
      "My name is  of the was not that, and he was--I had the his of a.    \"I, I had been, in the, and I had been his pictures--I had been the, and--I had been the his\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters() , lr=1e-4,\n",
    "    weight_decay=0.1\n",
    ")\n",
    "\n",
    "num_epochs=10\n",
    "train_losses,val_losses,tokens_seen=train_model_simple(\n",
    "    model,train_dataloader,val_dataloader,optimizer=optimizer\n",
    "    ,num_epochs=num_epochs,eval_freq=5,eval_iter=5,\n",
    "    start_context=\"My name is \",tokenizer=tokenizer,device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(\n",
    "    epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\"\n",
    "    )\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax2 = ax1.twiny() #1\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0) #2\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to('cpu')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_text:\n",
      " you are a really good  was not that the picture.\n",
      "\n",
      "\"I had the of a.\n",
      "\n",
      "\n",
      "\n",
      "\"I, I had been\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tiktoken.get_encoding('gpt2')\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"you are a really good \",tokenizer=tokenizer),\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M['context_length']\n",
    ")\n",
    "print(\"output_text:\\n\",token_ids_to_text(token_ids,tokenizer=tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "#temperature scaling \n",
    "\n",
    "vocab={\n",
    "\"hi\":0,\n",
    "\"I\":1,\n",
    "\"was\":2,\n",
    "\"trained\":3,\n",
    "\"by\":4,\n",
    "\"Bhavya\":5,\n",
    "\"Goyal\":6,\n",
    "\" \":7\n",
    "}\n",
    "inverse_vocab = {v:k for k ,v in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_token_logits = torch.tensor(\n",
    "[4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    0.0612,     0.0016,     0.0001,     0.5744,     0.0034,     0.0001,\n",
       "            0.0001,     0.3590])"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probas=torch.softmax(next_token_logits,dim=-1)\n",
    "next_token_id=torch.argmax(probas,dim=-1).item()\n",
    "next_token_id\n",
    "probas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained\n"
     ]
    }
   ],
   "source": [
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "next_token_id = torch.multinomial(probas , num_samples=1, replacement=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8])\n",
      "59 x hi\n",
      "2 x I\n",
      "0 x was\n",
      "574 x trained\n",
      "5 x by\n",
      "0 x Bhavya\n",
      "0 x Goyal\n",
      "360 x  \n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def print_sampled_tokens(probas):\n",
    "    torch.manual_seed(123)\n",
    "    sample = [\n",
    "        torch.multinomial(probas,num_samples=1).item()\n",
    "        for i in range(1000)\n",
    "\n",
    "    ]\n",
    "    sample_ids = torch.bincount(\n",
    "        torch.tensor(sample)\n",
    "    )\n",
    "    print(sample_ids.shape)\n",
    "    for i , freq in enumerate(sample_ids):\n",
    "        print(f\"{freq} x {inverse_vocab[i]}\")\n",
    "print(print_sampled_tokens(probas))        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_with_temp(logits,temp):\n",
    "    scaled_logits = logits / temp\n",
    "    return torch.softmax(scaled_logits,dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temperatures = [1,0.1,5]\n",
    "scaled_probas = [softmax_with_temp(next_token_logits,T) for T in temperatures]\n",
    "x=torch.arange(len(vocab))\n",
    "bar_width = 0.15\n",
    "fig, ax = plt.subplots(figsize=(5, 3))\n",
    "for i, T in enumerate(temperatures):\n",
    "    rects = ax.bar(x + i * bar_width, scaled_probas[i],\n",
    "          bar_width, label=f'Temperature = {T}')\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7])"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k=4\n",
    "top_logits, top_pos = torch.topk(next_token_logits,top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = torch.topk(next_token_logits,top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([6.7500, 6.2800, 4.5100, 1.6300]),\n",
       "indices=tensor([3, 7, 0, 4]))"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top logits:  tensor([6.7500, 6.2800, 4.5100, 1.6300])\n",
      "top positons:  tensor([3, 7, 0, 4])\n"
     ]
    }
   ],
   "source": [
    "print('top logits: ',top_logits)\n",
    "print('top positons: ',top_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.5100,   -inf,   -inf, 6.7500, 1.6300,   -inf,   -inf, 6.2800])\n"
     ]
    }
   ],
   "source": [
    "new_logits = torch.where(\n",
    "    condition=next_token_logits<top_logits[-1],\n",
    "    input=torch.tensor(float('-inf')),\n",
    "    other=next_token_logits\n",
    "\n",
    ")\n",
    "print(new_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k_probas=torch.softmax(new_logits,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx,max_new_tokens, context_size,\n",
    "             temperature=0.0,top_k=None,eos_id=None):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond=idx[: , -context_size:]\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits=model(idx_cond)\n",
    "            \n",
    "            \n",
    "        logits = logits[: ,-1 , :]\n",
    "        if top_k is not None:\n",
    "            top_logits, _ = torch.topk(logits,top_k)\n",
    "            min_val=top_logits[: , -1]\n",
    "            logits = torch.where(\n",
    "                logits < min_val,\n",
    "                torch.tensor(float('-inf'), device=logits.device),\n",
    "                logits\n",
    "            )\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "            probs=torch.softmax(logits,dim=-1)\n",
    "            idx_next = torch.multinomial(probs,num_samples=1)\n",
    "        else:\n",
    "            idx_next  = torch.argmax(logits,dim=-1,keepdim=True)\n",
    "        if idx_next==eos_id:\n",
    "            break\n",
    "        idx=torch.cat((idx,idx_next),dim=-1)\n",
    "\n",
    "    return idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_text: I had not with an up. \" was one felt have work my diagnosis \" by _ was up on, my Graftis one\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"I had\",tokenizer=tokenizer),\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M['context_length'],\n",
    "    top_k=30,\n",
    "    temperature=5,)\n",
    "print(\"output_text:\",token_ids_to_text(token_ids,tokenizer=tokenizer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hp/y1d826dx5fb1405ppnjjm4700000gn/T/ipykernel_24958/1438646223.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  newGPTMODEL.load_state_dict(torch.load(\"model.pth\",map_location=device))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading weights into new model \n",
    "\n",
    "newGPTMODEL = GPTModel(GPT_CONFIG_124M)\n",
    "newGPTMODEL.load_state_dict(torch.load(\"model.pth\",map_location=device))\n",
    "newGPTMODEL.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(\n",
    "    {\n",
    "        \"model_state_dict\":model.state_dict(),\n",
    "        \"model_optimizer\":optimizer.state_dict()\n",
    "    },\n",
    "    \"model_and_optimizer.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hp/y1d826dx5fb1405ppnjjm4700000gn/T/ipykernel_24958/2448505592.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(\n",
    "    \"model_and_optimizer.pth\",map_location=device\n",
    ")\n",
    "SECOND_GPT_MODEL = GPTModel(\n",
    "    GPT_CONFIG_124M\n",
    ")\n",
    "SECOND_GPT_MODEL.load_state_dict(\n",
    "    checkpoint['model_state_dict']\n",
    ")\n",
    "optimizer = torch.optim.AdamW(\n",
    "    SECOND_GPT_MODEL.parameters(),\n",
    "    lr=5e-4,\n",
    "    weight_decay=0.1\n",
    ")\n",
    "optimizer.load_state_dict(\n",
    "    checkpoint['model_optimizer']\n",
    ")\n",
    "SECOND_GPT_MODEL.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('gpt_download.py', <http.client.HTTPMessage at 0x9375cf1d0>)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "url = (\n",
    "\"https://raw.githubusercontent.com/rasbt/\"\n",
    "\"LLMs-from-scratch/main/ch05/\"\n",
    "\"01_main-chapter-code/gpt_download.py\"\n",
    ")\n",
    "filename = url.split('/')[-1]\n",
    "urllib.request.urlretrieve(url, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/checkpoint\n",
      "File already exists and is up-to-date: gpt2/124M/encoder.json\n",
      "File already exists and is up-to-date: gpt2/124M/hparams.json\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2/124M/vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "\n",
    "setting , params = download_and_load_gpt2(\n",
    "    model_size='124M' , models_dir=\"gpt2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n",
      "parameters dictionary keys: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"
     ]
    }
   ],
   "source": [
    "print(\"settings:\",setting) # similar to my defined gpt_config_124M\n",
    "\n",
    "print(\"parameters dictionary keys:\",params.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024, 768)\n"
     ]
    }
   ],
   "source": [
    "print(params['wpe'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_configs = {\n",
    "    \"gpt2-S (124M)\":{\"emb_dim\":768,\"n_layers\":12,\"n_heads\":12},\n",
    "    \"gpt2-M (355M)\":{\"emb_dim\":1024,\"n_layers\":24,\"n_heads\":16},\n",
    "    \"gpt2-L (774M)\":{\"emb_dim\":1280,\"n_layers\":36,\"n_heads\":20},\n",
    "    \"gpt2-XL (1558M)\":{\"emb_dim\":1600,\"n_layers\":48,\"n_heads\":25}\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt2-S (124M)\"\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "NEW_CONFIG.update(model_configs[model_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEW_CONFIG.update({'context_length':1024})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vocab_size': 50257,\n",
       " 'context_length': 1024,\n",
       " 'emb_dim': 768,\n",
       " 'n_heads': 12,\n",
       " 'n_layers': 12,\n",
       " 'drop_rate': 0.1,\n",
       " 'bias_': False}"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NEW_CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEW_CONFIG.update({\"bias_\":True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_MODEL_PRETRAINED_BY_OPENAI = GPTModel(\n",
    "    NEW_CONFIG\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign(left ,right):\n",
    "    if left.shape !=  right.shape:\n",
    "        raise ValueError(\n",
    "            f'shape mismatch. Left:{left.shape} ,'\n",
    "            f\"Right: {right.shape}\"\n",
    "        )\n",
    "    return torch.nn.Parameter(torch.tensor(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_weights_into_gpt(gpt, params): #1\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
    "    for b in range(len(params[\"blocks\"])): #2\n",
    "        attention = gpt.trf_blocks[b].attention\n",
    "        q_w, k_w, v_w = np.split( #3\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        attention.W_query.weight = assign(\n",
    "            attention.W_query.weight, q_w.T)\n",
    "        attention.W_key.weight = assign(\n",
    "            attention.W_key.weight, k_w.T)\n",
    "        attention.W_value.weight = assign(\n",
    "            attention.W_value.weight, v_w.T)\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        attention.W_query.bias = assign(\n",
    "            attention.W_query.bias, q_b)\n",
    "        attention.W_key.bias = assign(\n",
    "            attention.W_key.bias, k_b)\n",
    "        attention.W_value.bias = assign(\n",
    "            attention.W_value.bias, v_b)\n",
    "        attention.out_proj.weight = assign(\n",
    "            attention.out_proj.weight,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        attention.out_proj.bias = assign(\n",
    "            attention.out_proj.bias,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm1.scale = assign(\n",
    "            gpt.trf_blocks[b].norm1.scale,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(\n",
    "            gpt.trf_blocks[b].norm1.shift,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(\n",
    "            gpt.trf_blocks[b].norm2.scale,\n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(\n",
    "            gpt.trf_blocks[b].norm2.shift,\n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): Gelu()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_weights_into_gpt(GPT_MODEL_PRETRAINED_BY_OPENAI, params)\n",
    "GPT_MODEL_PRETRAINED_BY_OPENAI.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output text:\n",
      " hi the Red Flag. He was one of course and one of our top five, but that does not mean the Red and Blue and Green will be our\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "token_ids=generate(\n",
    "    model=GPT_MODEL_PRETRAINED_BY_OPENAI,\n",
    "    idx=text_to_token_ids(text=\"hi\" ,tokenizer=tokenizer).to(device),\n",
    "    max_new_tokens=30,\n",
    "    context_size=NEW_CONFIG['context_length'],\n",
    "    top_k=10,\n",
    "    temperature=1.5\n",
    ")\n",
    "print(\"output text:\\n\",token_ids_to_text(token_ids,tokenizer=tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt2-XL (1558M)\"\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "NEW_CONFIG.update(model_configs[model_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEW_CONFIG.update({\"context_length\":1024})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vocab_size': 50257,\n",
       " 'context_length': 1024,\n",
       " 'emb_dim': 1600,\n",
       " 'n_heads': 25,\n",
       " 'n_layers': 48,\n",
       " 'drop_rate': 0.1,\n",
       " 'bias_': True,\n",
       " 'qkv_bias': True}"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NEW_CONFIG.update({\"bias_\": True})\n",
    "NEW_CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
