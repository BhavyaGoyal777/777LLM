{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CODING ATTENTION MECHANISM\n"
     ]
    }
   ],
   "source": [
    "print('CODING ATTENTION MECHANISM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hp/y1d826dx5fb1405ppnjjm4700000gn/T/ipykernel_4906/935272016.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(torch.rand(6,4))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.8398, 0.8042, 0.1213, 0.5309],\n",
       "        [0.6646, 0.4077, 0.0888, 0.2429],\n",
       "        [0.7053, 0.6216, 0.9188, 0.0185],\n",
       "        [0.8741, 0.0560, 0.9659, 0.0073],\n",
       "        [0.3628, 0.4197, 0.6444, 0.0099],\n",
       "        [0.5925, 0.9631, 0.6958, 0.9157]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "inputs=torch.tensor(torch.rand(6,4))\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9002, 0.6913, 1.5390, 1.7004, 0.9632, 1.2506])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding z3 a context vector for fourth token\n",
    "\n",
    "query4=inputs[3]\n",
    "query4 @ inputs.T  # 1x4  @   6x4 ------>  1x4 @ 4x6 = 1x6  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9002, 0.6913, 1.5390, 1.7004, 0.9632, 1.2506]) torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "#majddori method \n",
    "\n",
    "\n",
    "query4=inputs[3]\n",
    "attention_score_4=torch.empty(inputs.shape[0])\n",
    "for i, x_i in enumerate(inputs):\n",
    "    attention_score_4[i]=torch.dot(x_i,query4)\n",
    "print(attention_score_4,attention_score_4.shape)    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.8398, 0.8042, 0.1213, 0.5309])\n",
      "tensor([0.6646, 0.4077, 0.0888, 0.2429])\n",
      "tensor([0.7053, 0.6216, 0.9188, 0.0185])\n",
      "tensor([0.8741, 0.0560, 0.9659, 0.0073])\n",
      "tensor([0.3628, 0.4197, 0.6444, 0.0099])\n",
      "tensor([0.5925, 0.9631, 0.6958, 0.9157])\n"
     ]
    }
   ],
   "source": [
    "for i in inputs:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9002)\n",
      "tensor(0.9002)\n"
     ]
    }
   ],
   "source": [
    "majduri_dot_product=0\n",
    "for idx,element in enumerate(inputs[0]):\n",
    "    majduri_dot_product+=inputs[0][idx] * query4[idx]\n",
    "print(majduri_dot_product)\n",
    "print(torch.dot(inputs[0],query4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention scores without normalization : tensor([0.9002, 0.6913, 1.5390, 1.7004, 0.9632, 1.2506])\n",
      "Attention score with normalization     : tensor([0.1278, 0.0981, 0.2185, 0.2414, 0.1367, 0.1775])\n"
     ]
    }
   ],
   "source": [
    "#normalizing \n",
    "\n",
    "attn_weights_4_normlaized = attention_score_4 / attention_score_4.sum()\n",
    "print(f'Attention scores without normalization : {attention_score_4}')\n",
    "print(f'Attention score with normalization     : {attn_weights_4_normlaized}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_weights_4_normlaized.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.1188, 0.0964, 0.2251, 0.2645, 0.1265, 0.1687])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# applying softmax instead of normalization\n",
    "\n",
    "def naive_softmax(x): \n",
    "    print(torch.exp(x).shape) \n",
    "    return torch.exp(x)/torch.exp(x).sum(dim=0)\n",
    "\n",
    "attn_weights_4_sft=naive_softmax(attention_score_4)\n",
    "\n",
    "attn_weights_4_sft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_weights_4_sft.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights using softmax by pytorch tensor([0.1188, 0.0964, 0.2251, 0.2645, 0.1265, 0.1687])\n",
      "Attnetion scores sum is 1.0\n"
     ]
    }
   ],
   "source": [
    "# optimized way by pytorch\n",
    "\n",
    "attn_weights_4_sft_optzd=torch.softmax(attention_score_4,dim=0)\n",
    "\n",
    "print(f'Attention weights using softmax by pytorch {attn_weights_4_sft_optzd}')\n",
    "\n",
    "print(f'Attnetion scores sum is {attn_weights_4_sft_optzd.sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6997, 0.5051, 0.6841, 0.2483])\n"
     ]
    }
   ],
   "source": [
    "# okay now we will apply attention scores to their respective vectors and then sum it \n",
    "\n",
    "query=inputs[3] #this is the 4th token\n",
    "\n",
    "context_vec_4=torch.zeros(query.shape)\n",
    "\n",
    "for i,x_i in enumerate(inputs):\n",
    "    context_vec_4+=attn_weights_4_sft_optzd[i] * x_i\n",
    "\n",
    "print(context_vec_4)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6997, 0.5051, 0.6841, 0.2483])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(attn_weights_4_sft_optzd,inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.6485, 1.0258, 1.2135, 0.9002, 0.7257, 1.8426],\n",
      "        [1.0258, 0.6749, 0.8083, 0.6913, 0.4719, 1.0707],\n",
      "        [1.2135, 0.8083, 1.7284, 1.5390, 1.1091, 1.6728],\n",
      "        [0.9002, 0.6913, 1.5390, 1.7004, 0.9632, 1.2506],\n",
      "        [0.7257, 0.4719, 1.1091, 0.9632, 0.7231, 1.0766],\n",
      "        [1.8426, 1.0707, 1.6728, 1.2506, 1.0766, 2.6011]])\n"
     ]
    }
   ],
   "source": [
    "# now calculating for every token in the input \n",
    "\n",
    "attention_score_input=torch.empty(6,6)\n",
    "\n",
    "for i , x_i in enumerate(inputs):\n",
    "    for j , x_j in enumerate(inputs):\n",
    "        attention_score_input[i,j]=torch.dot(x_i,x_j)\n",
    "\n",
    "print(attention_score_input)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.6485, 1.0258, 1.2135, 0.9002, 0.7257, 1.8426],\n",
       "        [1.0258, 0.6749, 0.8083, 0.6913, 0.4719, 1.0707],\n",
       "        [1.2135, 0.8083, 1.7284, 1.5390, 1.1091, 1.6728],\n",
       "        [0.9002, 0.6913, 1.5390, 1.7004, 0.9632, 1.2506],\n",
       "        [0.7257, 0.4719, 1.1091, 0.9632, 0.7231, 1.0766],\n",
       "        [1.8426, 1.0707, 1.6728, 1.2506, 1.0766, 2.6011]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(inputs,inputs.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_score_input_sft_nrmlzd=torch.softmax(attention_score_input,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.softmax(attention_score_input,dim=1),dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6864, 0.6531, 0.5439, 0.4199],\n",
       "        [0.6871, 0.5944, 0.5598, 0.3479],\n",
       "        [0.6851, 0.5683, 0.6572, 0.3041],\n",
       "        [0.6997, 0.5051, 0.6841, 0.2483],\n",
       "        [0.6786, 0.5614, 0.6342, 0.2982],\n",
       "        [0.6703, 0.6960, 0.5966, 0.4804]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vectors=torch.matmul(attention_score_input_sft_nrmlzd,inputs)\n",
    "context_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we start with trainable matrices with matrix q,k,v\n",
    "input_vec_token2=inputs[1]\n",
    "\n",
    "d_in=inputs.shape[1]\n",
    "d_out=3\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn \n",
    "torch.manual_seed(6969)\n",
    "\n",
    "w_key=torch.nn.Parameter(torch.rand(d_in,d_out),requires_grad=False)\n",
    "w_query=torch.nn.Parameter(torch.rand(d_in,d_out),requires_grad=False)\n",
    "w_value=torch.nn.Parameter(torch.rand(d_in,d_out,requires_grad=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_2=inputs[1]@w_query\n",
    "key_2=inputs[1]@w_key\n",
    "value_2=inputs[1]@w_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0028, 0.4865, 0.6946])\n",
      "tensor([0.7034, 0.8019, 0.6788])\n",
      "tensor([0.8855, 0.8590, 0.4732], grad_fn=<SqueezeBackward4>)\n"
     ]
    }
   ],
   "source": [
    "print(query_2)\n",
    "print(key_2)\n",
    "print(value_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys=inputs @ w_key #6x4 4x3 ---> 6x3\n",
    "values=inputs @ w_value#6x4 4x3 ---> 6x3\n",
    "query=inputs @ w_query #6x4 4x3 ---> 6x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 3])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(15.9836)\n"
     ]
    }
   ],
   "source": [
    "#now we find attention matrix we use quey vector of that token fow whihc we want to find its corresponding vector\n",
    "\n",
    "query_2=query[1]\n",
    "\n",
    "attention_scores2=torch.matmul(query_2,keys.T)  #1x3  @  6x3 ---> 1x6\n",
    "\n",
    "print(attention_scores2.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0000)\n"
     ]
    }
   ],
   "source": [
    "# now we scale the logits first then apply spftmax\n",
    "attention_scores2=torch.softmax(attention_scores2 / d_out**0.5,dim=0)\n",
    "ct1=torch.matmul(attention_scores2,values)  #1x6  @6x3-----> 1x3\n",
    "print(attention_scores2.sum(dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0702, 1.4964, 1.0350], grad_fn=<SqueezeBackward4>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class SelfAttention_v1(nn.Module):\n",
    "    def __init__(self, d_in,d_out):  \n",
    "        super().__init__()\n",
    "        self.w_query=nn.Parameter(torch.rand(d_in,d_out))\n",
    "        self.W_key=nn.Parameter(torch.rand(d_in,d_out))\n",
    "        self.W_value=nn.Parameter(torch.rand(d_in,d_out))\n",
    "\n",
    "    def forward(self,x):\n",
    "        keys= x @ self.W_key   \n",
    "        print('kdone')         \n",
    "        queries= x @ self.w_query\n",
    "        print('qdone') \n",
    "        values=x @ self.W_value\n",
    "        print('vdone') \n",
    "        attn_scores = queries @ keys.T\n",
    "        attn_weights = torch.softmax(\n",
    "            attn_scores / keys.shape[-1]**0.5 , dim=-1\n",
    "        )   \n",
    "        context_vec = attn_weights @ values\n",
    "        return context_vec\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kdone\n",
      "qdone\n",
      "vdone\n",
      "tensor([[1.1773, 1.3761, 1.1954],\n",
      "        [1.0623, 1.2755, 1.0853],\n",
      "        [1.1467, 1.3518, 1.1668],\n",
      "        [1.0986, 1.3097, 1.1207],\n",
      "        [1.0454, 1.2633, 1.0700],\n",
      "        [1.2563, 1.4486, 1.2726]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(69)\n",
    "\n",
    "sa_v1=SelfAttention_v1(d_in,d_out)\n",
    "print(sa_v1(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2243,  0.0456, -0.0402],\n",
      "        [-0.2239,  0.0622, -0.0334],\n",
      "        [-0.2226,  0.0685, -0.0314],\n",
      "        [-0.2230,  0.0851, -0.0246],\n",
      "        [-0.2225,  0.0700, -0.0307],\n",
      "        [-0.2241,  0.0335, -0.0454]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#using nn.linear as it has he/xavier weight initializaton\n",
    "\n",
    "class SelfAttention_v2(nn.Module):\n",
    "    def __init__(self,d_in,d_out,bias_=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.w_keys_v2=nn.Linear(d_in,d_out,bias=bias_)\n",
    "        self.w_query_v2=nn.Linear(d_in,d_out,bias=bias_)\n",
    "        self.w_values_v2=nn.Linear(d_in,d_out,bias=bias_)\n",
    "\n",
    "    def forward(self,x):\n",
    "        keys_matrix_v2=self.w_keys_v2(x)\n",
    "        values_matrix_v2=self.w_values_v2(x)\n",
    "        query_matrix_v2=self.w_query_v2(x)\n",
    "\n",
    "        attention_scores_matirx=query_matrix_v2 @ keys_matrix_v2.T\n",
    "\n",
    "        atteniton_weights=torch.softmax(\n",
    "            attention_scores_matirx / keys_matrix_v2.shape[-1]**0.5,dim=-1\n",
    "        )\n",
    "        context_vectors_v2=atteniton_weights @ values_matrix_v2\n",
    "\n",
    "        return context_vectors_v2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "torch.manual_seed(69)\n",
    "\n",
    "sa_v2=SelfAttention_v2(d_in,d_out)\n",
    "print(sa_v2(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries= sa_v2.w_query_v2(inputs)\n",
    "keys= sa_v2.w_query_v2(inputs)\n",
    "values=sa_v2.w_values_v2(inputs)\n",
    "\n",
    "attention_scores=keys @ values.T\n",
    "attention_weights=torch.softmax(\n",
    "    attention_scores / keys.shape[-1] ** 0.5 ,dim=-1\n",
    ")\n",
    "\n",
    "context_vectors = attention_weights @ values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
       "       grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_weights.sum(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hp/y1d826dx5fb1405ppnjjm4700000gn/T/ipykernel_4906/1546787270.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  mac1=torch.tensor(torch.rand(11,100)).to(device)\n",
      "/var/folders/hp/y1d826dx5fb1405ppnjjm4700000gn/T/ipykernel_4906/1546787270.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  mac2=torch.tensor(torch.rand(11,100)).to(device)\n"
     ]
    }
   ],
   "source": [
    "mac1=torch.tensor(torch.rand(11,100)).to(device)\n",
    "mac2=torch.tensor(torch.rand(11,100)).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = attention_scores.shape[0]\n",
    "mask = torch.tril( \n",
    "    torch.ones(context_length,context_length)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_attn=attention_scores * mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0590, -0.0000,  0.0000, -0.0000,  0.0000,  0.0000],\n",
       "        [-0.0598, -0.0513,  0.0000, -0.0000,  0.0000, -0.0000],\n",
       "        [-0.0502, -0.0436, -0.1549, -0.0000, -0.0000, -0.0000],\n",
       "        [-0.1310, -0.0710, -0.2404, -0.1792, -0.0000, -0.0000],\n",
       "        [-0.0197, -0.0217, -0.0984, -0.1233, -0.0645, -0.0000],\n",
       "        [-0.0470, -0.0808,  0.0925, -0.1022,  0.0957,  0.0860]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_attn = masked_attn / masked_attn.sum(-1,keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000,  0.0000, -0.0000,  0.0000, -0.0000,  0.0000],\n",
       "        [ 0.6874,  0.3126, -0.0000,  0.0000, -0.0000, -0.0000],\n",
       "        [ 0.4561,  0.2101,  0.3338,  0.0000,  0.0000, -0.0000],\n",
       "        [ 0.5398,  0.1553,  0.2348,  0.0700,  0.0000, -0.0000],\n",
       "        [ 0.2532,  0.1477,  0.2997,  0.1503,  0.1492, -0.0000],\n",
       "        [ 0.2681,  0.2446, -0.1251,  0.0553, -0.0982,  0.6553]],\n",
       "       grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
       "       grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_attn.sum(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
