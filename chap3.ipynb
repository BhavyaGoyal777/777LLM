{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CODING ATTENTION MECHANISM\n"
     ]
    }
   ],
   "source": [
    "print('CODING ATTENTION MECHANISM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hp/y1d826dx5fb1405ppnjjm4700000gn/T/ipykernel_4906/935272016.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(torch.rand(6,4))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.8398, 0.8042, 0.1213, 0.5309],\n",
       "        [0.6646, 0.4077, 0.0888, 0.2429],\n",
       "        [0.7053, 0.6216, 0.9188, 0.0185],\n",
       "        [0.8741, 0.0560, 0.9659, 0.0073],\n",
       "        [0.3628, 0.4197, 0.6444, 0.0099],\n",
       "        [0.5925, 0.9631, 0.6958, 0.9157]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "inputs=torch.tensor(torch.rand(6,4))\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9002, 0.6913, 1.5390, 1.7004, 0.9632, 1.2506])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding z3 a context vector for fourth token\n",
    "\n",
    "query4=inputs[3]\n",
    "query4 @ inputs.T  # 1x4  @   6x4 ------>  1x4 @ 4x6 = 1x6  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9002, 0.6913, 1.5390, 1.7004, 0.9632, 1.2506]) torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "#majddori method \n",
    "\n",
    "\n",
    "query4=inputs[3]\n",
    "attention_score_4=torch.empty(inputs.shape[0])\n",
    "for i, x_i in enumerate(inputs):\n",
    "    attention_score_4[i]=torch.dot(x_i,query4)\n",
    "print(attention_score_4,attention_score_4.shape)    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.8398, 0.8042, 0.1213, 0.5309])\n",
      "tensor([0.6646, 0.4077, 0.0888, 0.2429])\n",
      "tensor([0.7053, 0.6216, 0.9188, 0.0185])\n",
      "tensor([0.8741, 0.0560, 0.9659, 0.0073])\n",
      "tensor([0.3628, 0.4197, 0.6444, 0.0099])\n",
      "tensor([0.5925, 0.9631, 0.6958, 0.9157])\n"
     ]
    }
   ],
   "source": [
    "for i in inputs:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9002)\n",
      "tensor(0.9002)\n"
     ]
    }
   ],
   "source": [
    "majduri_dot_product=0\n",
    "for idx,element in enumerate(inputs[0]):\n",
    "    majduri_dot_product+=inputs[0][idx] * query4[idx]\n",
    "print(majduri_dot_product)\n",
    "print(torch.dot(inputs[0],query4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention scores without normalization : tensor([0.9002, 0.6913, 1.5390, 1.7004, 0.9632, 1.2506])\n",
      "Attention score with normalization     : tensor([0.1278, 0.0981, 0.2185, 0.2414, 0.1367, 0.1775])\n"
     ]
    }
   ],
   "source": [
    "#normalizing \n",
    "\n",
    "attn_weights_4_normlaized = attention_score_4 / attention_score_4.sum()\n",
    "print(f'Attention scores without normalization : {attention_score_4}')\n",
    "print(f'Attention score with normalization     : {attn_weights_4_normlaized}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_weights_4_normlaized.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.1188, 0.0964, 0.2251, 0.2645, 0.1265, 0.1687])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# applying softmax instead of normalization\n",
    "\n",
    "def naive_softmax(x): \n",
    "    print(torch.exp(x).shape) \n",
    "    return torch.exp(x)/torch.exp(x).sum(dim=0)\n",
    "\n",
    "attn_weights_4_sft=naive_softmax(attention_score_4)\n",
    "\n",
    "attn_weights_4_sft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_weights_4_sft.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights using softmax by pytorch tensor([0.1188, 0.0964, 0.2251, 0.2645, 0.1265, 0.1687])\n",
      "Attnetion scores sum is 1.0\n"
     ]
    }
   ],
   "source": [
    "# optimized way by pytorch\n",
    "\n",
    "attn_weights_4_sft_optzd=torch.softmax(attention_score_4,dim=0)\n",
    "\n",
    "print(f'Attention weights using softmax by pytorch {attn_weights_4_sft_optzd}')\n",
    "\n",
    "print(f'Attnetion scores sum is {attn_weights_4_sft_optzd.sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6997, 0.5051, 0.6841, 0.2483])\n"
     ]
    }
   ],
   "source": [
    "# okay now we will apply attention scores to their respective vectors and then sum it \n",
    "\n",
    "query=inputs[3] #this is the 4th token\n",
    "\n",
    "context_vec_4=torch.zeros(query.shape)\n",
    "\n",
    "for i,x_i in enumerate(inputs):\n",
    "    context_vec_4+=attn_weights_4_sft_optzd[i] * x_i\n",
    "\n",
    "print(context_vec_4)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6997, 0.5051, 0.6841, 0.2483])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(attn_weights_4_sft_optzd,inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.6485, 1.0258, 1.2135, 0.9002, 0.7257, 1.8426],\n",
      "        [1.0258, 0.6749, 0.8083, 0.6913, 0.4719, 1.0707],\n",
      "        [1.2135, 0.8083, 1.7284, 1.5390, 1.1091, 1.6728],\n",
      "        [0.9002, 0.6913, 1.5390, 1.7004, 0.9632, 1.2506],\n",
      "        [0.7257, 0.4719, 1.1091, 0.9632, 0.7231, 1.0766],\n",
      "        [1.8426, 1.0707, 1.6728, 1.2506, 1.0766, 2.6011]])\n"
     ]
    }
   ],
   "source": [
    "# now calculating for every token in the input \n",
    "\n",
    "attention_score_input=torch.empty(6,6)\n",
    "\n",
    "for i , x_i in enumerate(inputs):\n",
    "    for j , x_j in enumerate(inputs):\n",
    "        attention_score_input[i,j]=torch.dot(x_i,x_j)\n",
    "\n",
    "print(attention_score_input)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.6485, 1.0258, 1.2135, 0.9002, 0.7257, 1.8426],\n",
       "        [1.0258, 0.6749, 0.8083, 0.6913, 0.4719, 1.0707],\n",
       "        [1.2135, 0.8083, 1.7284, 1.5390, 1.1091, 1.6728],\n",
       "        [0.9002, 0.6913, 1.5390, 1.7004, 0.9632, 1.2506],\n",
       "        [0.7257, 0.4719, 1.1091, 0.9632, 0.7231, 1.0766],\n",
       "        [1.8426, 1.0707, 1.6728, 1.2506, 1.0766, 2.6011]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(inputs,inputs.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_score_input_sft_nrmlzd=torch.softmax(attention_score_input,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.softmax(attention_score_input,dim=1),dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6864, 0.6531, 0.5439, 0.4199],\n",
       "        [0.6871, 0.5944, 0.5598, 0.3479],\n",
       "        [0.6851, 0.5683, 0.6572, 0.3041],\n",
       "        [0.6997, 0.5051, 0.6841, 0.2483],\n",
       "        [0.6786, 0.5614, 0.6342, 0.2982],\n",
       "        [0.6703, 0.6960, 0.5966, 0.4804]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vectors=torch.matmul(attention_score_input_sft_nrmlzd,inputs)\n",
    "context_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we start with trainable matrices with matrix q,k,v\n",
    "input_vec_token2=inputs[1]\n",
    "\n",
    "d_in=inputs.shape[1]\n",
    "d_out=3\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn \n",
    "torch.manual_seed(6969)\n",
    "\n",
    "w_key=torch.nn.Parameter(torch.rand(d_in,d_out),requires_grad=False)\n",
    "w_query=torch.nn.Parameter(torch.rand(d_in,d_out),requires_grad=False)\n",
    "w_value=torch.nn.Parameter(torch.rand(d_in,d_out,requires_grad=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_2=inputs[1]@w_query\n",
    "key_2=inputs[1]@w_key\n",
    "value_2=inputs[1]@w_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0028, 0.4865, 0.6946])\n",
      "tensor([0.7034, 0.8019, 0.6788])\n",
      "tensor([0.8855, 0.8590, 0.4732], grad_fn=<SqueezeBackward4>)\n"
     ]
    }
   ],
   "source": [
    "print(query_2)\n",
    "print(key_2)\n",
    "print(value_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys=inputs @ w_key #6x4 4x3 ---> 6x3\n",
    "values=inputs @ w_value#6x4 4x3 ---> 6x3\n",
    "query=inputs @ w_query #6x4 4x3 ---> 6x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 3])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(15.9836)\n"
     ]
    }
   ],
   "source": [
    "#now we find attention matrix we use quey vector of that token fow whihc we want to find its corresponding vector\n",
    "\n",
    "query_2=query[1]\n",
    "\n",
    "attention_scores2=torch.matmul(query_2,keys.T)  #1x3  @  6x3 ---> 1x6\n",
    "\n",
    "print(attention_scores2.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0000)\n"
     ]
    }
   ],
   "source": [
    "# now we scale the logits first then apply spftmax\n",
    "attention_scores2=torch.softmax(attention_scores2 / d_out**0.5,dim=0)\n",
    "ct1=torch.matmul(attention_scores2,values)  #1x6  @6x3-----> 1x3\n",
    "print(attention_scores2.sum(dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0702, 1.4964, 1.0350], grad_fn=<SqueezeBackward4>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class SelfAttention_v1(nn.Module):\n",
    "    def __init__(self, d_in,d_out):  \n",
    "        super().__init__()\n",
    "        self.w_query=nn.Parameter(torch.rand(d_in,d_out))\n",
    "        self.W_key=nn.Parameter(torch.rand(d_in,d_out))\n",
    "        self.W_value=nn.Parameter(torch.rand(d_in,d_out))\n",
    "\n",
    "    def forward(self,x):\n",
    "        keys= x @ self.W_key   \n",
    "        print('kdone')         \n",
    "        queries= x @ self.w_query\n",
    "        print('qdone') \n",
    "        values=x @ self.W_value\n",
    "        print('vdone') \n",
    "        attn_scores = queries @ keys.T\n",
    "        attn_weights = torch.softmax(\n",
    "            attn_scores / keys.shape[-1]**0.5 , dim=-1\n",
    "        )   \n",
    "        context_vec = attn_weights @ values\n",
    "        return context_vec\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kdone\n",
      "qdone\n",
      "vdone\n",
      "tensor([[1.1773, 1.3761, 1.1954],\n",
      "        [1.0623, 1.2755, 1.0853],\n",
      "        [1.1467, 1.3518, 1.1668],\n",
      "        [1.0986, 1.3097, 1.1207],\n",
      "        [1.0454, 1.2633, 1.0700],\n",
      "        [1.2563, 1.4486, 1.2726]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(69)\n",
    "\n",
    "sa_v1=SelfAttention_v1(d_in,d_out)\n",
    "print(sa_v1(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2243,  0.0456, -0.0402],\n",
      "        [-0.2239,  0.0622, -0.0334],\n",
      "        [-0.2226,  0.0685, -0.0314],\n",
      "        [-0.2230,  0.0851, -0.0246],\n",
      "        [-0.2225,  0.0700, -0.0307],\n",
      "        [-0.2241,  0.0335, -0.0454]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#using nn.linear as it has he/xavier weight initializaton\n",
    "\n",
    "class SelfAttention_v2(nn.Module):\n",
    "    def __init__(self,d_in,d_out,bias_=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.w_keys_v2=nn.Linear(d_in,d_out,bias=bias_)\n",
    "        self.w_query_v2=nn.Linear(d_in,d_out,bias=bias_)\n",
    "        self.w_values_v2=nn.Linear(d_in,d_out,bias=bias_)\n",
    "\n",
    "    def forward(self,x):\n",
    "        keys_matrix_v2=self.w_keys_v2(x)\n",
    "        values_matrix_v2=self.w_values_v2(x)\n",
    "        query_matrix_v2=self.w_query_v2(x)\n",
    "\n",
    "        attention_scores_matirx=query_matrix_v2 @ keys_matrix_v2.T\n",
    "\n",
    "        atteniton_weights=torch.softmax(\n",
    "            attention_scores_matirx / keys_matrix_v2.shape[-1]**0.5,dim=-1\n",
    "        )\n",
    "        context_vectors_v2=atteniton_weights @ values_matrix_v2\n",
    "\n",
    "        return context_vectors_v2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "torch.manual_seed(69)\n",
    "\n",
    "sa_v2=SelfAttention_v2(d_in,d_out)\n",
    "print(sa_v2(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries= sa_v2.w_query_v2(inputs)\n",
    "keys= sa_v2.w_query_v2(inputs)\n",
    "values=sa_v2.w_values_v2(inputs)\n",
    "\n",
    "attention_scores=keys @ values.T\n",
    "attention_weights=torch.softmax(\n",
    "    attention_scores / keys.shape[-1] ** 0.5 ,dim=-1\n",
    ")\n",
    "\n",
    "context_vectors = attention_weights @ values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
       "       grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_weights.sum(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hp/y1d826dx5fb1405ppnjjm4700000gn/T/ipykernel_4906/1546787270.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  mac1=torch.tensor(torch.rand(11,100)).to(device)\n",
      "/var/folders/hp/y1d826dx5fb1405ppnjjm4700000gn/T/ipykernel_4906/1546787270.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  mac2=torch.tensor(torch.rand(11,100)).to(device)\n"
     ]
    }
   ],
   "source": [
    "mac1=torch.tensor(torch.rand(11,100)).to(device)\n",
    "mac2=torch.tensor(torch.rand(11,100)).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = attention_scores.shape[0]\n",
    "mask = torch.tril( \n",
    "    torch.ones(context_length,context_length)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_attn=attention_scores * mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0590, -0.0000,  0.0000, -0.0000,  0.0000,  0.0000],\n",
       "        [-0.0598, -0.0513,  0.0000, -0.0000,  0.0000, -0.0000],\n",
       "        [-0.0502, -0.0436, -0.1549, -0.0000, -0.0000, -0.0000],\n",
       "        [-0.1310, -0.0710, -0.2404, -0.1792, -0.0000, -0.0000],\n",
       "        [-0.0197, -0.0217, -0.0984, -0.1233, -0.0645, -0.0000],\n",
       "        [-0.0470, -0.0808,  0.0925, -0.1022,  0.0957,  0.0860]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_attn = masked_attn / masked_attn.sum(-1,keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0590, -0.0000,  0.0000, -0.0000,  0.0000,  0.0000],\n",
       "        [-0.0598, -0.0513,  0.0000, -0.0000,  0.0000, -0.0000],\n",
       "        [-0.0502, -0.0436, -0.1549, -0.0000, -0.0000, -0.0000],\n",
       "        [-0.1310, -0.0710, -0.2404, -0.1792, -0.0000, -0.0000],\n",
       "        [-0.0197, -0.0217, -0.0984, -0.1233, -0.0645, -0.0000],\n",
       "        [-0.0470, -0.0808,  0.0925, -0.1022,  0.0957,  0.0860]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0590, -0.1111, -0.2487, -0.6217, -0.3276,  0.0441],\n",
       "       grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_attn.sum(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 1., 1., 1., 1.],\n",
       "        [0., 0., 1., 1., 1., 1.],\n",
       "        [0., 0., 0., 1., 1., 1.],\n",
       "        [0., 0., 0., 0., 1., 1.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = torch.triu(\n",
    "    torch.ones(context_length,context_length)\n",
    "    ,diagonal=1\n",
    ")\n",
    "mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "masked = attention_scores.masked_fill(\n",
    "    mask.bool(),\n",
    "    -torch.inf\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0590,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
       "        [-0.0598, -0.0513,    -inf,    -inf,    -inf,    -inf],\n",
       "        [-0.0502, -0.0436, -0.1549,    -inf,    -inf,    -inf],\n",
       "        [-0.1310, -0.0710, -0.2404, -0.1792,    -inf,    -inf],\n",
       "        [-0.0197, -0.0217, -0.0984, -0.1233, -0.0645,    -inf],\n",
       "        [-0.0470, -0.0808,  0.0925, -0.1022,  0.0957,  0.0860]],\n",
       "       grad_fn=<MaskedFillBackward0>)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_weights = torch.softmax(\n",
    "    masked / keys.shape[-1] ** 0.5,dim=-1\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.4988, 0.5012, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3395, 0.3408, 0.3196, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2534, 0.2623, 0.2379, 0.2464, 0.0000, 0.0000],\n",
       "        [0.2053, 0.2051, 0.1962, 0.1934, 0.2001, 0.0000],\n",
       "        [0.1613, 0.1582, 0.1749, 0.1563, 0.1752, 0.1742]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 2., 0., 0., 2.],\n",
      "        [0., 0., 0., 2., 0., 0.],\n",
      "        [2., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 2., 2., 0.],\n",
      "        [2., 2., 2., 0., 0., 2.],\n",
      "        [0., 2., 0., 2., 0., 2.]])\n"
     ]
    }
   ],
   "source": [
    "# now we apply dropout to the attention scores \n",
    "\n",
    "torch.manual_seed(69)\n",
    "\n",
    "dropout=torch.nn.Dropout(0.5)\n",
    "example=torch.ones(6,6)\n",
    "print(dropout(example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.6791, 0.6817, 0.6392, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.5246, 0.4758, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.4101, 0.0000, 0.3868, 0.0000, 0.0000],\n",
      "        [0.0000, 0.3164, 0.3497, 0.3125, 0.3503, 0.0000]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "print(dropout(attn_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 6, 4])\n"
     ]
    }
   ],
   "source": [
    "batch=torch.stack((inputs,inputs),dim=0)\n",
    "print(batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalAttention(nn.Module):\n",
    "    def __init__(self,d_in,d_out,context_length,dropout,bias_=False):\n",
    "        super().__init__()\n",
    "        self.d_out=d_out\n",
    "        self.w_query=torch.nn.Linear(\n",
    "            d_in,d_out,bias_\n",
    "        )\n",
    "        self.w_key=torch.nn.Linear(\n",
    "            d_in,d_out,bias_\n",
    "        )\n",
    "        self.w_value=nn.Linear(\n",
    "            d_in,d_out,bias_\n",
    "        )\n",
    "        self.dropout=nn.Dropout(\n",
    "            dropout\n",
    "        )\n",
    "        self.register_buffer(\n",
    "            'mask',\n",
    "            torch.triu(torch.ones(context_length,context_length),diagonal=1)\n",
    "\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        b ,num_tokens,d_in = x.shape\n",
    "        keys=self.w_key(x)\n",
    "        values=self.w_value(x)\n",
    "        queries=self.w_query(x)\n",
    "\n",
    "        attn_scores=queries @ keys.transpose(1,2)\n",
    "        attn_scores.masked_fill_(\n",
    "            self.mask.bool()[:num_tokens , :num_tokens],-torch.inf)\n",
    "        attn_weights=torch.softmax(\n",
    "            attn_scores / keys.shape[-1] ** 0.5 , dim=-1\n",
    "        )\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        context_vec= attn_weights @ values\n",
    "\n",
    "        return context_vec\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0173,  0.8058],\n",
       "         [-0.0473,  0.6571],\n",
       "         [-0.0305,  0.4268],\n",
       "         [-0.2195,  0.6064],\n",
       "         [-0.1743,  0.4883],\n",
       "         [-0.0358,  0.4079]],\n",
       "\n",
       "        [[ 0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000],\n",
       "         [ 0.0057,  0.2674],\n",
       "         [-0.2195,  0.6064],\n",
       "         [-0.1925,  0.5513],\n",
       "         [-0.0865,  0.5450]]], grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "context_length = batch.shape[1]\n",
    "\n",
    "ca=CausalAttention(\n",
    "    d_in=4,\n",
    "    d_out=2,\n",
    "    context_length=context_length,\n",
    "\n",
    "    dropout=0.2\n",
    "\n",
    "\n",
    ")\n",
    "ca(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in , d_out , num_heads, dropout , context_length, bias_=False ):\n",
    "        super().__init__()\n",
    "        self.head_dim = d_out / num_heads\n",
    "\n",
    "        self.heads = nn.ModuleList([\n",
    "            CausalAttention(\n",
    "                d_in, d_out,\n",
    "                context_length, dropout, bias_\n",
    "            )\n",
    "            for _ in range(num_heads)]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.cat(\n",
    "            [head(x) for head in self.heads], dim=-1\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(69)\n",
    "context_length = batch.shape[1]\n",
    "print(batch.shape[1])\n",
    "print(batch.shape[2])\n",
    "\n",
    "mha=MultiHeadAttention(\n",
    "    d_in=4,\n",
    "  \n",
    "    dropout=0.2,\n",
    "    context_length=context_length,\n",
    "    num_heads=4,\n",
    "    d_out=4\n",
    "    \n",
    "\n",
    ")\n",
    "context_vectors=mha(batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6, 16])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert (d_out % num_heads == 0), \\\n",
    "        \"d_out must be divisible by num_heads\"\n",
    "        \n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads\n",
    "        \n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out, d_out)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.register_buffer(\n",
    "            \"mask\",\n",
    "            torch.triu(torch.ones(context_length, context_length),\n",
    "                      diagonal=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "        \n",
    "        # Linear transformations\n",
    "        keys = self.W_key(x)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "        \n",
    "        # Reshape to include heads dimension\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        \n",
    "        # Compute attention scores\n",
    "        attn_scores = queries @ keys.transpose(-2, -1)\n",
    "        \n",
    "        # Apply mask\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "        \n",
    "        # Compute attention weights\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "        \n",
    "        # Compute context vectors\n",
    "        context_vec = attn_weights @ values\n",
    "        context_vec = context_vec.transpose(1, 2).contiguous().view(b, num_tokens, self.d_out)\n",
    "        context_vec = self.out_proj(context_vec)\n",
    "        \n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.7047, -0.3305],\n",
      "         [ 0.6953, -0.3733],\n",
      "         [ 0.7038, -0.3727],\n",
      "         [ 0.7317, -0.3482],\n",
      "         [ 0.7134, -0.3794],\n",
      "         [ 0.7132, -0.3585]],\n",
      "\n",
      "        [[ 0.7047, -0.3305],\n",
      "         [ 0.6953, -0.3733],\n",
      "         [ 0.7038, -0.3727],\n",
      "         [ 0.7317, -0.3482],\n",
      "         [ 0.7134, -0.3794],\n",
      "         [ 0.7132, -0.3585]]], grad_fn=<ViewBackward0>)\n",
      "context_vecs.shape: torch.Size([2, 6, 2])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "batch_size, context_length, d_in = batch.shape\n",
    "d_out = 2\n",
    "mha = MultiHeadAttention(d_in=d_in, d_out=d_out, context_length=context_length, dropout=0.0, num_heads=2)\n",
    "context_vecs = mha(batch)\n",
    "print(context_vecs)\n",
    "print(\"context_vecs.shape:\", context_vecs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.2745, 0.6584, 0.2775, 0.8573],\n",
       "          [0.8993, 0.0390, 0.9268, 0.7388],\n",
       "          [0.7179, 0.7058, 0.9156, 0.4340]],\n",
       "\n",
       "         [[0.0772, 0.3565, 0.1479, 0.5331],\n",
       "          [0.4066, 0.2318, 0.4545, 0.9737],\n",
       "          [0.4606, 0.5159, 0.4220, 0.5786]]]])"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[[[0.2745, 0.6584, 0.2775, 0.8573], [0.8993, 0.0390, 0.9268, 0.7388],\n",
    "[0.7179, 0.7058, 0.9156, 0.4340]],\n",
    "\n",
    "[[0.0772, 0.3565, 0.1479, 0.5331],\n",
    "[0.4066, 0.2318, 0.4545, 0.9737],\n",
    "[0.4606, 0.5159, 0.4220, 0.5786]]]])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 3, 4])"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiHeadAttentionGPT2=MultiHeadAttention(\n",
    "    d_in=768,d_out=768,dropout=0.2,context_length=1024,num_heads=12,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
